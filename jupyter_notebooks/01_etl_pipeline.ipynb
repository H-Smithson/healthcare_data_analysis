{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0678d8cc",
   "metadata": {},
   "source": [
    "# Data Extraction, Transformation and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82512375",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Data cleaning and transformation to prepare data for analysis\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Raw data loaded from Health Insurance csv from Kaggle (local copy saved in data folder)\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Cleaned data is saved as insurance-cleaned.csv in the data folder\n",
    "* Dashboard ready transformed data is saved to dashboard_data.csv in the data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd5c13",
   "metadata": {},
   "source": [
    "# Import data and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2abf72",
   "metadata": {},
   "source": [
    "Install any packages needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used in the notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0a628",
   "metadata": {},
   "source": [
    "Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data frame from csv file and display first 5 rows\n",
    "df = pd.read_csv('../data/insurance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d275a3",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa6dcf",
   "metadata": {},
   "source": [
    "### Transform part one: Clean Data: Remove duplicates and handle missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69236d0a",
   "metadata": {},
   "source": [
    "Firstly, we checked for missing data. It turned out that there were no (0) missing values for the data analysed for any of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find missing data (code from the LMS and ChatGPT helped me make this):\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0eaca2",
   "metadata": {},
   "source": [
    "We then searched for duplicate data and removed it (ChatGPT helped me with this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399288b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Find and print duplicate rows (excluding first occurrence)\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(duplicates)\n",
    "\n",
    "# 🔹 Remove duplicates (keep first occurrence)\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "df_no_duplicates.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616aad08",
   "metadata": {},
   "source": [
    "### Transform data part two: Categorise data and check for outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a1392",
   "metadata": {},
   "source": [
    "We've added in a category for BMI (ChatGPT suggested some good category values for us and helped write quick code for it). Unreasonable values for when the data was collected (e.g someone having an age of 130) were also checked for and none appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8716f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize BMI\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif 18.5 <= bmi < 25:\n",
    "        return \"Normal\"\n",
    "    elif 25 <= bmi < 30:\n",
    "        return \"Overweight\"\n",
    "    else:\n",
    "        return \"Obese\"\n",
    "\n",
    "# Apply function to create a new column\n",
    "df['bmi_category'] = df['bmi'].apply(categorize_bmi)\n",
    "\n",
    "#Clean dataframe in place: fix types, strip spaces, handle missing, encode. (code from  ChatGPT helped me make this):\n",
    "def transform_clean(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    # strip and lower string columns\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "    # numeric coercion for known numeric columns\n",
    "    for col in ['age','bmi','children','charges']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # mapping / encoding (safe)\n",
    "    if 'smoker' in df.columns:\n",
    "        df['smoker'] = df['smoker'].str.lower().map({'no':0,'yes':1})\n",
    "    return df    \n",
    "\n",
    "#Check for unreasonable values (e.g unnrealistic values for BMI and age at the time of dataset being collected) and handle them.\n",
    "def validate_df(df):\n",
    "    errors = []\n",
    "    # shape\n",
    "    if df.empty:\n",
    "        errors.append(\"DataFrame is empty.\")\n",
    "    # ranges\n",
    "    if df['age'].min() < 0 or df['age'].max() > 130:\n",
    "        errors.append(\"Age out of expected range.\")\n",
    "        print(errors)\n",
    "    if (df['bmi'] < 10).any() or (df['bmi'] > 80).any():\n",
    "        errors.append(\"BMI has out-of-range values.\")\n",
    "        print(errors)\n",
    "    if (df['children'] < 0).any() or (df['children'] > 20).any():\n",
    "        errors.append(\"Children out-of-range.\")\n",
    "        print(errors)\n",
    "# === ETL Pipeline Wrapper ===\n",
    "def etl_pipeline(filepath: str):\n",
    "    \"\"\"\n",
    "    End-to-end ETL pipeline:\n",
    "    - Extract: Load dataset from CSV\n",
    "    - Transform: Clean, encode, and add BMI categories\n",
    "    - Load: Return a ready-to-analyze DataFrame\n",
    "    - Validate: Run quality checks and print issues\n",
    "    \"\"\"\n",
    "    # Extract\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Transform (clean + encode)\n",
    "    df = transform_clean(df)\n",
    "\n",
    "    # Add BMI categories\n",
    "    df[\"bmi_category\"] = df[\"bmi\"].apply(categorize_bmi)\n",
    "\n",
    "    # Validate\n",
    "    validate_df(df)\n",
    "\n",
    "    # Load (return cleaned DataFrame)\n",
    "    return df\n",
    "\n",
    "# === Run the ETL pipeline ===\n",
    "df_clean = etl_pipeline(\"../data/insurance.csv\")\n",
    "\n",
    "# Quick check\n",
    "df_clean.head()\n",
    "\n",
    "# Show first 10 rows to check\n",
    "transform_clean(df)\n",
    "validate_df(df)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd38bb",
   "metadata": {},
   "source": [
    "Code has also been used to automate the ETL process and makes it reusable for future datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee319252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# ADDITION: Automated ETL Pipeline \n",
    "# -----------------------------\n",
    "def etl_pipeline(file_path):\n",
    "    \"\"\"\n",
    "    Automated ETL pipeline for insurance dataset:\n",
    "    - Extract\n",
    "    - Transform\n",
    "    - Load\n",
    "    - Validate\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # BMI categories\n",
    "    def categorize_bmi(bmi):\n",
    "        if bmi < 18.5: return \"Underweight\"\n",
    "        elif 18.5 <= bmi < 25: return \"Normal\"\n",
    "        elif 25 <= bmi < 30: return \"Overweight\"\n",
    "        else: return \"Obese\"\n",
    "    df['bmi_category'] = df['bmi'].apply(categorize_bmi)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df['smoker'] = df['smoker'].str.lower().map({'no':0,'yes':1})\n",
    "    df['region'] = df['region'].astype('category').cat.codes\n",
    "    \n",
    "    # Validate ranges\n",
    "    assert df['age'].between(0,130).all(), \"Age out of range\"\n",
    "    assert df['bmi'].between(10,80).all(), \"BMI out of range\"\n",
    "    assert df['children'].between(0,20).all(), \"Children out of range\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "df_clean = etl_pipeline('../data/insurance.csv')\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4b959",
   "metadata": {},
   "source": [
    "## Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41238e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export cleaned data to csv file in data folder\n",
    "df_clean.to_csv(\"../data/insurance-cleaned.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61629093",
   "metadata": {},
   "source": [
    "# 🖥️ Dashboard Preparation\n",
    "\n",
    "This code block prepares the dataset for a business intelligence dashboard (e.g., Tableau or Power BI).  \n",
    "\n",
    "**Steps included:**\n",
    "\n",
    "1. Identify continuous and categorical columns based on the dataset guide.  \n",
    "2. Scale continuous numeric columns (`age` and `bmi`) for better visual consistency.  \n",
    "3. Ensure categorical columns, including `bmi_category`, are treated as strings for BI tools.  \n",
    "4. Precompute aggregations (mean `charges`) by `region`, `smoker`, `children`, and `bmi_category`.  \n",
    "5. Export the cleaned, dashboard-ready dataset to `dashboard_data.csv`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1️⃣ Define columns based on data guide\n",
    "# -------------------------------\n",
    "continuous_cols = ['age', 'bmi']\n",
    "categorical_cols = ['sex', 'children', 'smoker', 'region']\n",
    "target_col = 'charges'\n",
    "\n",
    "print(\"Continuous numeric columns to scale:\", continuous_cols)\n",
    "print(\"Categorical columns for BI:\", categorical_cols + ['bmi_category'])\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Scale continuous numeric columns\n",
    "# -------------------------------\n",
    "df_scaled = df_clean.copy()  # Keep original data intact\n",
    "\n",
    "for col in continuous_cols:\n",
    "    mean = df_scaled[col].mean()\n",
    "    std = df_scaled[col].std()\n",
    "    df_scaled[col] = (df_scaled[col] - mean) / std\n",
    "\n",
    "print(\"\\nScaled continuous numeric features:\\n\")\n",
    "print(df_scaled[continuous_cols].head())\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Ensure categorical columns are strings for BI\n",
    "# -------------------------------\n",
    "for col in categorical_cols + ['bmi_category']:  # include existing BMI category\n",
    "    df_scaled[col] = df_scaled[col].astype(str)\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Precompute aggregations for dashboard visualisations\n",
    "# -------------------------------\n",
    "aggregations = {\n",
    "    'region': df_scaled.groupby('region')[target_col].mean().reset_index(),\n",
    "    'smoker': df_scaled.groupby('smoker')[target_col].mean().reset_index(),\n",
    "    'children': df_scaled.groupby('children')[target_col].mean().reset_index(),\n",
    "    'bmi_category': df_scaled.groupby('bmi_category')[target_col].mean().reset_index()\n",
    "}\n",
    "\n",
    "print(\"\\nAggregations ready for dashboard visualisations.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5️⃣ Optionally export for Tableau / Power BI\n",
    "# -------------------------------\n",
    "df_scaled.to_csv('../data/dashboard_data.csv', index=False)\n",
    "print(\"\\nDashboard-ready dataset saved as 'dashboard_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcda3e3",
   "metadata": {},
   "source": [
    "# Conclusions and Next Steps\n",
    "* ETL Pipeline created for future use.\n",
    "* Data checked for outliers, duplicates and unreasonable values. \n",
    "* Feature engineering used to categorize BMI.\n",
    "* Data Cleaned and ready for use in visualisations / dashboarding.\n",
    "* Data saved in relevant folder, seperated with original file, cleaned file and dashboard file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
